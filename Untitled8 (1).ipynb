{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElszuAY57t9x",
        "outputId": "b1752dcb-97fe-4b77-bc03-8d5ec4bcb5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1. Gerekli Kütüphaneler\n",
        "# ===============================\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"✅ Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuyKg0a-CgDg",
        "outputId": "0df57057-f9e5-415d-b53e-c716d545e777"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 2. Parametreler\n",
        "# ===============================\n",
        "model_name = \"hustvl/yolos-tiny\"\n",
        "dataset_root = \"/content/drive/MyDrive/ship_dataset_2\"  # dataset root\n",
        "checkpoint_dir = \"/content/drive/MyDrive/yolos_checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "subset_ratio = 0.2       # %20 veri ile eğitim\n",
        "num_epochs = 5           # Epoch sayısı\n",
        "batch_size = 4\n",
        "learning_rate = 5e-5\n",
        "iou_threshold = 0.5"
      ],
      "metadata": {
        "id": "aXTOZquxCpZK"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 3. Model ve Processor\n",
        "# ===============================\n",
        "processor = YolosImageProcessor.from_pretrained(model_name)\n",
        "model = YolosForObjectDetection.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "_FeaMNpqCx1s"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 4. Checkpoint Fonksiyonları\n",
        "# ===============================\n",
        "def save_checkpoint(epoch, model, optimizer, scaler, path):\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scaler_state\": scaler.state_dict()\n",
        "    }, path)\n",
        "    print(f\"✅ Checkpoint kaydedildi: {path}\")\n",
        "\n",
        "def load_checkpoint(path, model, optimizer, scaler):\n",
        "    checkpoint = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"model_state\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
        "    scaler.load_state_dict(checkpoint[\"scaler_state\"])\n",
        "    start_epoch = checkpoint[\"epoch\"] + 1\n",
        "    print(f\"✅ Checkpoint yüklendi. Başlangıç epoch: {start_epoch}\")\n",
        "    return start_epoch\n",
        "\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"yolos_last.pth\")\n"
      ],
      "metadata": {
        "id": "qOwEN21NC4B9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class COCODataset(Dataset):\n",
        "    def __init__(self, images_dir, ann_path, processor, subset_ratio=1.0):\n",
        "        self.images_dir = images_dir\n",
        "        self.processor = processor\n",
        "        with open(ann_path) as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        self.images_info = {img[\"id\"]: img for img in data[\"images\"]}\n",
        "        self.annotations = data[\"annotations\"]\n",
        "\n",
        "        # Anotasyonları image_id bazlı grupla\n",
        "        self.img_to_anns = {}\n",
        "        for ann in self.annotations:\n",
        "            self.img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
        "\n",
        "        self.image_ids = list(self.images_info.keys())\n",
        "        if subset_ratio < 1.0:\n",
        "            random.shuffle(self.image_ids)\n",
        "            self.image_ids = self.image_ids[:int(len(self.image_ids) * subset_ratio)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.images_info[img_id]\n",
        "        img_path = os.path.join(self.images_dir, img_info[\"file_name\"])\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        anns = self.img_to_anns.get(img_id, [])\n",
        "\n",
        "        encoding = self.processor(images=image, annotations={\"image_id\": img_id, \"annotations\": anns}, return_tensors=\"pt\")\n",
        "\n",
        "        # encoding[\"pixel_values\"] shape: (1, C, H, W) → squeeze yapacağız\n",
        "        pixel_values = encoding[\"pixel_values\"].squeeze(0)\n",
        "        labels = encoding[\"labels\"]  # list of dict\n",
        "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n"
      ],
      "metadata": {
        "id": "G7Hi9EZqC8Y6"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n",
        "    labels = [item[\"labels\"][0] for item in batch]  # HuggingFace processor list döndürüyor\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n"
      ],
      "metadata": {
        "id": "yhgpY7ogDAK-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 7. Dataloaders\n",
        "# ===============================\n",
        "train_dataset = COCODataset(\n",
        "    images_dir=os.path.join(dataset_root, \"train/images\"),\n",
        "    ann_path=os.path.join(dataset_root, \"train/annotations.json\"),\n",
        "    processor=processor,\n",
        "    subset_ratio=subset_ratio\n",
        ")\n",
        "\n",
        "val_dataset = COCODataset(\n",
        "    images_dir=os.path.join(dataset_root, \"valid/images\"),\n",
        "    ann_path=os.path.join(dataset_root, \"valid/annotations.json\"),\n",
        "    processor=processor,\n",
        "    subset_ratio=subset_ratio\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "BEgZ-zTiDD16"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8. IoU Hesaplama\n",
        "# ===============================\n",
        "def compute_iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = area1 + area2 - intersection\n",
        "    return intersection / union if union > 0 else 0\n"
      ],
      "metadata": {
        "id": "T6mYS-rKDJCc"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 9. Değerlendirme Fonksiyonu\n",
        "# ===============================\n",
        "def evaluate(model, dataloader, iou_threshold=0.5):\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "    ious = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            outputs = model(pixel_values=pixel_values)\n",
        "            target_sizes = torch.tensor([pixel_values.shape[-2:]]).to(device)\n",
        "\n",
        "            results = processor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]\n",
        "            gt_boxes = batch[\"labels\"][0][\"boxes\"].tolist()\n",
        "\n",
        "            pred_boxes = results[\"boxes\"].tolist()\n",
        "            pred_scores = results[\"scores\"].tolist()\n",
        "\n",
        "            matched_gt = set()\n",
        "            for pb, score in zip(pred_boxes, pred_scores):\n",
        "                best_iou = 0\n",
        "                best_idx = -1\n",
        "                for idx, gb in enumerate(gt_boxes):\n",
        "                    if idx in matched_gt:\n",
        "                        continue\n",
        "                    iou = compute_iou(pb, gb)\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_idx = idx\n",
        "                all_scores.append(score)\n",
        "                all_labels.append(1 if best_iou >= iou_threshold else 0)\n",
        "                if best_iou >= iou_threshold:\n",
        "                    matched_gt.add(best_idx)\n",
        "                    ious.append(best_iou)\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(all_labels, all_scores)\n",
        "    ap = average_precision_score(all_labels, all_scores)\n",
        "    return precision, recall, ap, ious\n"
      ],
      "metadata": {
        "id": "r0WFGuDLDQ7K"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 10. Optimizer ve AMP\n",
        "# ===============================\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Checkpoint yükleme\n",
        "start_epoch = 0\n",
        "if os.path.exists(checkpoint_path):\n",
        "    start_epoch = load_checkpoint(checkpoint_path, model, optimizer, scaler)\n",
        "else:\n",
        "    print(\"Checkpoint bulunamadı. Sıfırdan başlıyoruz.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc3DoVHiDY3q",
        "outputId": "60e6b71f-99eb-40a3-8482-ee8f3ead123f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint bulunamadı. Sıfırdan başlıyoruz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-52431295.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 11. Eğitim Döngüsü\n",
        "# ===============================\n",
        "all_precisions = []\n",
        "all_recalls = []\n",
        "all_aps = []\n",
        "epoch_ious = []\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "        pixel_values = batch[\"pixel_values\"].to(device)\n",
        "        labels = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "            loss = outputs.loss\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # ✅ Checkpoint Kaydet\n",
        "    save_checkpoint(epoch, model, optimizer, scaler, checkpoint_path)\n",
        "\n",
        "    # ✅ Değerlendirme\n",
        "    precision, recall, ap, ious = evaluate(model, val_loader, iou_threshold)\n",
        "    all_precisions.append(precision)\n",
        "    all_recalls.append(recall)\n",
        "    all_aps.append(ap)\n",
        "    epoch_ious.append(sum(ious) / len(ious) if len(ious) > 0 else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXUHiVoBDaYS",
        "outputId": "789eb1f2-db70-41c9-bbb0-735a9dadea43"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1:   0%|          | 0/1391 [00:00<?, ?it/s]/tmp/ipython-input-1458453940.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Training Epoch 1: 100%|██████████| 1391/1391 [2:26:31<00:00,  6.32s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.0888\n",
            "✅ Checkpoint kaydedildi: /content/drive/MyDrive/yolos_checkpoints/yolos_last.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 794/794 [07:45<00:00,  1.70it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "Training Epoch 2:   0%|          | 0/1391 [00:00<?, ?it/s]/tmp/ipython-input-1458453940.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Training Epoch 2: 100%|██████████| 1391/1391 [1:46:45<00:00,  4.61s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 1.4159\n",
            "✅ Checkpoint kaydedildi: /content/drive/MyDrive/yolos_checkpoints/yolos_last.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 794/794 [05:02<00:00,  2.63it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "Training Epoch 3:   0%|          | 0/1391 [00:00<?, ?it/s]/tmp/ipython-input-1458453940.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Training Epoch 3: 100%|██████████| 1391/1391 [1:46:36<00:00,  4.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.1922\n",
            "✅ Checkpoint kaydedildi: /content/drive/MyDrive/yolos_checkpoints/yolos_last.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 794/794 [05:04<00:00,  2.61it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "Training Epoch 4:   0%|          | 0/1391 [00:00<?, ?it/s]/tmp/ipython-input-1458453940.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Training Epoch 4:  46%|████▌     | 637/1391 [48:50<57:08,  4.55s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 12. Eğitim Bittikten Sonra Tek Seferde Grafikler\n",
        "# ===============================\n",
        "plt.figure(figsize=(12, 5))\n",
        "for i, (p, r, ap) in enumerate(zip(all_precisions, all_recalls, all_aps)):\n",
        "    plt.plot(r, p, label=f'Epoch {i+1} (AP={ap:.3f})')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve for All Epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(epoch_ious)+1), epoch_ious, marker='o')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Average IoU\")\n",
        "plt.title(\"Average IoU per Epoch\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RUKajjU7Dh72"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
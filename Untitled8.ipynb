{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElszuAY57t9x",
        "outputId": "2a23a1a6-c42f-4736-f459-85388dee0a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Kaydetme yolu\n",
        "checkpoint_dir = \"/content/drive/MyDrive/yolos_checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 1. Gerekli Kütüphaneler\n",
        "# ======================================\n",
        "!pip install transformers datasets torch torchvision tqdm matplotlib pycocotools --quiet\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "def save_checkpoint(epoch, model, optimizer, scaler, path):\n",
        "    checkpoint = {\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scaler_state\": scaler.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, path)\n",
        "    print(f\"✅ Checkpoint kaydedildi: {path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZNpdYD-c7ni",
        "outputId": "749ed1b0-d4fd-40b6-b933-e08c69f4a4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 2. Parametreler\n",
        "# ======================================\n",
        "dataset_root = \"/content/drive/MyDrive/ship_dataset\"  # <-- Kendi yolunu yaz\n",
        "subset_ratio = 0.01  # %5 veri kullan\n",
        "num_epochs = 10\n",
        "batch_size = 2\n",
        "learning_rate = 5e-5\n",
        "iou_threshold = 0.5\n",
        "def load_checkpoint(path, model, optimizer, scaler):\n",
        "    checkpoint = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"model_state\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
        "    scaler.load_state_dict(checkpoint[\"scaler_state\"])\n",
        "    start_epoch = checkpoint[\"epoch\"] + 1\n",
        "    print(f\"✅ Checkpoint yüklendi. Başlangıç epoch: {start_epoch}\")\n",
        "    return start_epoch"
      ],
      "metadata": {
        "id": "wrzkq-wadBz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 3. Model ve Processor\n",
        "# ======================================\n",
        "model_name = \"hustvl/yolos-tiny\"\n",
        "processor = YolosImageProcessor.from_pretrained(model_name)\n",
        "model = YolosForObjectDetection.from_pretrained(model_name).to(device)\n"
      ],
      "metadata": {
        "id": "QlhRKySRdJOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 4. Dataset Sınıfı\n",
        "# ======================================\n",
        "class COCODataset(Dataset):\n",
        "    def __init__(self, images_dir, ann_path, processor, subset_ratio=1.0):\n",
        "        self.images_dir = images_dir\n",
        "        self.processor = processor\n",
        "\n",
        "        with open(ann_path) as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        self.images_info = {img[\"id\"]: img for img in data[\"images\"]}\n",
        "        self.annotations = data[\"annotations\"]\n",
        "\n",
        "        # Anotasyonları image_id bazlı grupla\n",
        "        self.img_to_anns = {}\n",
        "        for ann in self.annotations:\n",
        "            self.img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
        "\n",
        "        self.image_ids = list(self.images_info.keys())\n",
        "        if subset_ratio < 1.0:\n",
        "            random.shuffle(self.image_ids)\n",
        "            self.image_ids = self.image_ids[:int(len(self.image_ids) * subset_ratio)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.images_info[img_id]\n",
        "        img_path = os.path.join(self.images_dir, img_info[\"file_name\"])\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # GT kutuları ve etiketler\n",
        "        anns = self.img_to_anns.get(img_id, [])\n",
        "        boxes = []\n",
        "        classes = []\n",
        "        for ann in anns:\n",
        "            x, y, w, h = ann[\"bbox\"]\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            classes.append(ann[\"category_id\"])\n",
        "\n",
        "        target = {\n",
        "            \"image_id\": torch.tensor([img_id]),\n",
        "            \"class_labels\": torch.tensor(classes),\n",
        "            \"boxes\": torch.tensor(boxes)\n",
        "        }\n",
        "\n",
        "        encoding = self.processor(images=image, annotations={\"image_id\": img_id, \"annotations\": anns}, return_tensors=\"pt\")\n",
        "        # encoding = {k: v.squeeze(0) for k, v in encoding.items()} # Remove this line\n",
        "        encoding[\"labels\"] = target\n",
        "\n",
        "        return encoding"
      ],
      "metadata": {
        "id": "ZJD1tXoLdOwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 5. Collate Function\n",
        "# ======================================\n",
        "def collate_fn(batch):\n",
        "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch]).squeeze(1)\n",
        "    labels = [item[\"labels\"] for item in batch]\n",
        "    # Assuming image_id is present in each item of the batch list from __getitem__\n",
        "    image_ids = torch.tensor([item[\"image_id\"] for item in batch]) # Collect image_ids\n",
        "\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels, \"image_id\": image_ids} # Include image_id"
      ],
      "metadata": {
        "id": "pbvdeqOddT3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 5. Collate Function (Moved Here)\n",
        "# ======================================\n",
        "def collate_fn(batch):\n",
        "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch]).squeeze(1)\n",
        "    labels = [item[\"labels\"] for item in batch]\n",
        "    # Removed image_id from returned dictionary as it caused KeyError\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# 6. Dataset ve Dataloader\n",
        "# ======================================\n",
        "model.train()\n",
        "\n",
        "train_dataset = COCODataset(\n",
        "    images_dir=os.path.join(dataset_root, \"/content/drive/MyDrive/ship_dataset_2/train/images\"),\n",
        "    ann_path=os.path.join(dataset_root, \"/content/drive/MyDrive/ship_dataset_2/train/annotations.json\"),\n",
        "    processor=processor,\n",
        "    subset_ratio=subset_ratio\n",
        ")\n",
        "\n",
        "val_dataset = COCODataset(\n",
        "    images_dir=os.path.join(dataset_root, \"/content/drive/MyDrive/ship_dataset_2/valid/images\"),\n",
        "    ann_path=os.path.join(dataset_root, \"/content/drive/MyDrive/ship_dataset_2/valid/annotations.json\"),\n",
        "    processor=processor,\n",
        "    subset_ratio=subset_ratio\n",
        ")\n",
        "\n",
        "# Initialize DataLoaders using the collate_fn defined in this cell\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
        "\n",
        "# ======================================\n",
        "# Eğitim Döngüsü\n",
        "# ======================================\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTnDw41xd-lu",
        "outputId": "3ed433f0-fea4-4a66-b9f6-deb33cb9f9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 278, Val samples: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 139/139 [11:57<00:00,  5.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2491.3993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 139/139 [10:09<00:00,  4.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 2503.8701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 139/139 [10:09<00:00,  4.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 2485.0298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 139/139 [10:12<00:00,  4.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 2498.8376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 139/139 [10:10<00:00,  4.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 2487.6417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 139/139 [10:08<00:00,  4.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 2495.7568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 139/139 [10:08<00:00,  4.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 2496.7572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 139/139 [10:11<00:00,  4.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 2483.2017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 139/139 [10:09<00:00,  4.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 2496.6878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 139/139 [10:10<00:00,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 2477.6435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Optimizer\n",
        "# ======================================\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scaler = torch.cuda.amp.GradScaler()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIkAIutfAKVf",
        "outputId": "7f835ec5-f2d9-4ee9-c936-f6e83ff4102a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3295774581.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 8. IoU Hesaplama Fonksiyonu\n",
        "# ======================================\n",
        "def compute_iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = area1 + area2 - intersection\n",
        "    return intersection / union if union > 0 else 0"
      ],
      "metadata": {
        "id": "j2UvqeX1AP--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 9. Değerlendirme Fonksiyonu\n",
        "# ======================================\n",
        "def evaluate(model, dataloader, iou_threshold=0.5):\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "    ious = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            outputs = model(pixel_values=pixel_values)\n",
        "            target_sizes = torch.tensor([pixel_values.shape[-2:]]).to(device)\n",
        "\n",
        "            results = processor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]\n",
        "            gt_boxes = batch[\"labels\"][0][\"boxes\"].tolist()\n",
        "\n",
        "            pred_boxes = results[\"boxes\"].tolist()\n",
        "            pred_scores = results[\"scores\"].tolist()\n",
        "\n",
        "            matched_gt = set()\n",
        "            for pb, score in zip(pred_boxes, pred_scores):\n",
        "                best_iou = 0\n",
        "                best_idx = -1\n",
        "                for idx, gb in enumerate(gt_boxes):\n",
        "                    if idx in matched_gt:\n",
        "                        continue\n",
        "                    iou = compute_iou(pb, gb)\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_idx = idx\n",
        "                all_scores.append(score)\n",
        "                all_labels.append(1 if best_iou >= iou_threshold else 0)\n",
        "                if best_iou >= iou_threshold:\n",
        "                    matched_gt.add(best_idx)\n",
        "                    ious.append(best_iou)\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(all_labels, all_scores)\n",
        "    ap = average_precision_score(all_labels, all_scores)\n",
        "    return precision, recall, ap, ious\n"
      ],
      "metadata": {
        "id": "-o4FwBRIATQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint dosyası\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"yolos_last.pth\")\n",
        "\n",
        "# Eğer checkpoint varsa yükle\n",
        "start_epoch = 0\n",
        "if os.path.exists(checkpoint_path):\n",
        "    start_epoch = load_checkpoint(checkpoint_path, model, optimizer, scaler)\n",
        "else:\n",
        "    print(\"Checkpoint bulunamadı. Sıfırdan başlıyoruz.\")\n",
        "\n",
        "# Eğitim döngüsü\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "        pixel_values = batch[\"pixel_values\"].to(device)\n",
        "        labels = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "            loss = outputs.loss\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # ✅ Checkpoint kaydet\n",
        "    save_checkpoint(epoch, model, optimizer, scaler, checkpoint_path)\n",
        "\n",
        "    # Değerlendirme\n",
        "    precision, recall, ap, ious = evaluate(model, val_loader, iou_threshold)\n",
        "\n",
        "    # Grafikleri çiz\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(recall, precision, label=f'AP={ap:.4f}')\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Precision-Recall Curve\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(ious, bins=20, range=(0, 1))\n",
        "    plt.xlabel(\"IoU\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"IoU Distribution\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPpi4n6XAXh8",
        "outputId": "caedadad-e574-4c59-aa0b-71e1f76062b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Checkpoint yüklendi. Başlangıç epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2:   0%|          | 0/139 [00:00<?, ?it/s]/tmp/ipython-input-1196960734.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Training Epoch 2:  75%|███████▍  | 104/139 [07:16<02:23,  4.11s/it]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}